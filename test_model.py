import numpy as np
import sg_utils as utils
import cap_eval_utils
from IPython.core.debugger import Tracer
# import caffe

def load_model(model_name, snapshot):
  """
  Load the model from file. Includes pointers to the prototxt file, 
  caffemodel file name, and other settings - image mean, base_image_size, vocab 
  """
  # model = utils.load_variables(
  # model.net = caffe.Net(model['prototxt_file'], model['caffemodel_file'], caffe.TEST)
  # return model

def output_words(detection_file, eval_file, functional_words, threshold_metric, output_metric):
  """
  Output the words as generated by the model.
  """

def test_model(imdb, model, detection_file = None):
  """
  Tests model and stores detections on disk
  """
  N_WORDS = len(model['vocab']['words'])
  sc = np.zeros((imdb.num_images, N_WORDS), dtype=np.float)
  prob = np.zeros((imdb.num_images, N_WORDS), dtype=np.float)
  for i in xrange(len(imdb.image_index)):
    im = utils.color(cv2.imread(imdb.image_path_at(i)))
    sc[i,:], prob[i,:] = test_img(im, net, model['base_image_size'], model['means'])

  utils.save_variables(detection_file, [sc, prob, vocab, imdb, snapshot],
    ['sc', 'prob', 'vocab', 'imdb', 'snapshot'], overwrite = True)

def benchmark(imdb, vocab, gt_label, num_references, detection_file, eval_file = None):
  # Get ground truth
  # counts = get_vocab_counts(imdb.image_index, coco_caps, max_cap, vocab)
  dt = utils.scio.loadmat(detection_file)
  mil_prob = dt['mil_prob'];
  
  # Benchmark the output, and return a result struct
  P     = np.zeros(mil_prob.shape, dtype          = np.float)
  R     = np.zeros(mil_prob.shape, dtype          = np.float)
  score = np.zeros(mil_prob.shape, dtype          = np.float)
  ap    = np.zeros((1,len(vocab['words'])), dtype = np.float)
  for i in range(len(vocab['words'])):
    P[:,i], R[:,i], score[:,i], ap[0,i] = cap_eval_utils.calc_pr_ovr(gt_label[:,i], mil_prob[:,i], num_references)
    # print '{:20s}: {:.3f}'.format(vocab['words'][i], ap[0,i]*100) 
  details = {'precision': P, 'recall': R, 'ap': ap, 'score': score}; 
  
  # Collect statistics over the POS
  for pos in list(set(vocab['poss'])):
    ind = [i for i,x in enumerate(vocab['poss']) if pos == x]
    print "{:5s} [{:3d}] : {:.2f} {:.2f} ".format(pos, len(ind), 100*np.mean(ap[0, ind]), 100*np.mean(ap[0, ind]))
  
  ind = range(len(vocab['words'])); pos = 'all';
  print "{:5s} [{:3d}] : {:.2f} {:.2f} ".format(pos, len(ind), 100*np.mean(ap[0, ind]), 100*np.mean(ap[0, ind]))

  return details

def test_img(im, net, base_image_size, means):
  """
  Calls Caffe to get output for this image
  """
  # Resize image
  im_orig = im.astype(np.float32, copy=True)
  im_orig -= cfg.PIXEL_MEANS
  
  im = upsample_image(im_orig, base_image_size)
  im = np.transpose(im, axes = (2, 0, 1))
  
  # Pass into Caffe
  net.forward()

  # Get outputs and return them 

def upsample_image(im, sz):
  h = im.shape[0]
  w = im.shape[1]
  s = max(h, w)
  I_out = np.zeros((sz, sz, 3), dtype = np.float);
  I = cv2.resize(im, None, None, fx = sz/s, fy = sz/s, interpolation=cv2.INTER_LINEAR); 
  SZ = I.shape;
  I_out[0:I.shape[0], 0:I.shape[1],:] = I;
  return I_out, I, SZ
